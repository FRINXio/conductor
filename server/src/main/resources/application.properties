#
#  Copyright 2021 Netflix, Inc.
#  <p>
#  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
#  the License. You may obtain a copy of the License at
#  <p>
#  http://www.apache.org/licenses/LICENSE-2.0
#  <p>
#  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
#  an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
#  specific language governing permissions and limitations under the License.
#

spring.application.name=conductor
springdoc.api-docs.path=/api-docs

conductor.db.type=postgres
spring.datasource.url=jdbc:postgresql://localhost:5432/postgres
spring.datasource.username=postgres
spring.datasource.password=postgres

conductor.indexing.enabled=false

#Dynomite Cluster details.
#format is host:port:rack separated by semicolon
conductor.redis.hosts=host1:port:rack;host2:port:rack:host3:port:rack

#namespace for the keys stored in Dynomite/Redis
conductor.redis.workflowNamespacePrefix=

#namespace prefix for the dyno queues
conductor.redis.queueNamespacePrefix=

#no. of threads allocated to dyno-queues
queues.dynomite.threads=10

# By default with dynomite, we want the repair service enabled
conductor.workflow-repair-service.enabled=true

#non-quorum port used to connect to local redis.  Used by dyno-queues
conductor.redis.queuesNonQuorumPort=22122

# For a single node dynomite or redis server, make sure the value below is set to same as rack specified in the "workflow.dynomite.cluster.hosts" property.
conductor.redis.availabilityZone=us-east-1c

#Transport address to elasticsearch
conductor.elasticsearch.url=localhost:9300

#Name of the elasticsearch cluster
conductor.elasticsearch.indexName=conductor

#Elasticsearch major release version.
conductor.elasticsearch.version=6
#conductor.elasticsearch.version=7

# Default event queue type to listen on for wait task
conductor.default-event-queue.type=sqs

#zookeeper
# conductor.zookeeper-lock.connectionString=host1.2181,host2:2181,host3:2181
# conductor.zookeeper-lock.sessionTimeoutMs
# conductor.zookeeper-lock.connectionTimeoutMs
# conductor.zookeeper-lock.namespace

#disable locking during workflow execution
conductor.app.workflow-execution-lock-enabled=false
conductor.workflow-execution-lock.type=noop_lock

#Redis cluster settings for locking module
# conductor.redis-lock.serverType=single
#Comma separated list of server nodes
# conductor.redis-lock.serverAddress=redis://127.0.0.1:6379
#Redis sentinel master name
# conductor.redis-lock.serverMasterName=master
# conductor.redis-lock.namespace

#Following properties set for using AMQP events and tasks with conductor:
#(To enable support of AMQP queues)
#conductor.event-queues.amqp.enabled=true

# Here are the settings with default values:
#conductor.event-queues.amqp.hosts=<rabbitmq serverip>
#conductor.event-queues.amqp.username=<username>
#conductor.event-queues.amqp.password=<password>

#conductor.event-queues.amqp.virtualHost=/
#conductor.event-queues.amqp.port=5672
#conductor.event-queues.amqp.useNio=false
#conductor.event-queues.amqp.batchSize=1

#conductor.event-queues.amqp.pollTimeDuration=100ms

#conductor.event-queues.amqp.useExchange=true( exchange or queue)
#conductor.event-queues.amqp.listenerQueuePrefix=myqueue
# Use durable queue ?
#conductor.event-queues.amqp.durable=false
# Use exclusive queue ?
#conductor.event-queues.amqp.exclusive=false
# Enable support of priorities on queue. Set the max priority on message.
# Setting is ignored if the value is lower or equals to 0
#conductor.event-queues.amqp.maxPriority=-1

# To enable Workflow/Task Summary Input/Output JSON Serialization, use the following:
# conductor.app.summary-input-output-json-serialization.enabled=true

# Additional modules for metrics collection exposed to Prometheus (optional)
# conductor.metrics-prometheus.enabled=true
# management.endpoints.web.exposure.include=prometheus

# Additional modules for metrics collection exposed to Datadog (optional)
management.metrics.export.datadog.enabled=${conductor.metrics-datadog.enabled:false}
management.metrics.export.datadog.api-key=${conductor.metrics-datadog.api-key:}



# All parameters can be specified as an environment variables in docker compose file by substituting dots for undserscores
# e.g use workflow_elasticsearch_url=VALUE to specify workflow.elasticsearch.url parameter

# NOTE: Configuration files overwrite the environment variables, to use an environment variable for configuration
# you must REMOVE the appropriate parameter from the configuration file first!

# Servers
#conductor.grpc-server.enabled=false
conductor.app.ownerEmailMandatory=false

# Hikari pool sizes are -1 by default and prevent startup
spring.datasource.hikari.maximumPoolSize=40
spring.datasource.hikari.minimumIdle=20
spring.datasource.hikari.idleTimeout=10
# Needed for single node ES cluster
conductor.elasticsearch.clusterHealthColor=yellow

#conductor.indexing.enabled=true

# Set elasticsearch version
#conductor.elasticsearch.version=6

# Transport address to elasticsearch
#conductor.elasticsearch.url=http://elasticsearch:9200

# Name of the elasticsearch cluster
conductor.elasticsearch.indexPrefix=conductor

# Additional modules (optional)
# conductor.additional.modules=class_extending_com.google.inject.AbstractModule
# Additional modules for metrics collection (optional)
conductor.additional.modules=com.netflix.conductor.contribs.metrics.MetricsRegistryModule,com.netflix.conductor.contribs.metrics.LoggingMetricsModule
conductor.metrics-logger.enabled=true
conductor.metrics-logger.reportPeriodSeconds=15

# Load sample kitchen sink workflow
#loadSample=false

# Increase payload threshold limits for transferring big schemas to PostgreSQL
conductor.app.workflowInputPayloadSizeThreshold=1
conductor.app.workflowOutputPayloadSizeThreshold=1
conductor.app.maxWorkflowInputPayloadSizeThreshold=1024000
conductor.app.maxWorkflowOutputPayloadSizeThreshold=1024000
conductor.app.taskInputPayloadSizeThreshold=1
conductor.app.taskOutputPayloadSizeThreshold=1
conductor.app.maxTaskInputPayloadSizeThreshold=1024000
conductor.app.maxTaskOutputPayloadSizeThreshold=1024000

# PostgreSQL External Payload Storage variables
conductor.external-payload-storage.type=postgres
conductor.external-payload-storage.postgres.conductor-url=http://localhost:8080
conductor.external-payload-storage.postgres.max-data-rows=1000000
conductor.external-payload-storage.postgres.max-data-days=0
conductor.external-payload-storage.postgres.max-data-months=0
conductor.external-payload-storage.postgres.max-data-years=1

conductor.external-payload-storage.postgres.url=jdbc:postgresql://localhost:5432/postgres
conductor.external-payload-storage.postgres.username=postgres
conductor.external-payload-storage.postgres.password=postgres

conductor.app.taskExecutionPostponeDuration=0
